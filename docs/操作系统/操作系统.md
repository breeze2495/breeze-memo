## 



## 一 操作系统基础





## 二 进程与线程

### 2.1 进程与线程

- **进程：** 
  - 一个正在执行的程序。
  - 资源调度的基本单位
- **线程：**
  - 一个进程由多个线程组成
  - CPU调度与执行的基本单位



### 2.2 进程的几种状态

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。



### 2.3 进程间的通信方式

`(IPC Internal - Process - C)`

#### 2.3.1 管道 / 匿名管道 (pipe)

- 管道是**半双工的**，实质是一个**内核缓冲区**，一端将数据写入，另一端读取
- 只能用于**父子进程或者兄弟进程**之间(具有**亲缘关系**的进程)
- 单独构成一个文件系统(不属于某种文件系统)，只存在于内存中
- 当缓冲区读空或者写满时，有一定的规则会控制相应的读/写进程进入等待队列

- **局限性:**
  - 单项数据流
  - 只能具有亲缘关系的进程间
  - 缓冲区有限（存在于内存中，管道创建时，为缓冲区分配一个页面大小
  - 管道传送的是无格式字节流，这就要求管道读写两端事先约定好数据格式，比如多少字节算一个消息等等



#### 2.3.2 有名管道 (FIFO)

- 匿名管道由于没有名字只能用于亲缘关系的进程间通信。为了克服这一缺点，提出了有名管道
- 提供了一个**路径名**与之关联，因此不存在亲缘关系的进程，只要访问该路径，就能彼此通过有名管道通信
- **先进先出**，不支持诸如lseek()等文件定位操作
- 名字存在于文件系统中，内容存放在内存中



#### 2.3.3 信号 (signal)

- 信号时linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程而无需知道该进程的状态
- 如果该进程处于阻塞状态，则该信号就有内核将其保存起来，直到该进程恢复执行并传递给它为止
- 如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消才被传递给该进程



#### 2.3.4 消息队列(message queue)

- 消息队列是存放在内核中的消息链表，具有特定格式，每个消息队列由消息队列标识符表示
- 与管道不同的是消息队列存放在内核中，只有在内核重启或者显示删除时，该消息队列才会被真正删除
- 另外与管道不同的是，消息队列在某个进程往一个队列写入之前，并不需要另外某个进程在该队列上等待消息的到达

- **特点：**
  - 允许一个或多个进程向它写入/读取消息
  - 可以实现消息的随机查询，不一定以先进先出的次序读取，也可以按消息的类型读取，比FIFO更有优势
  - 克服了信号承载信息量少，管道只能承载无格式字节流以及管道缓冲区大小受限 等缺陷
  - 目前主要有两种类型的消息队列：
    - Posix消息队列
    - System V消息队列(目前大量使用)： 随内核持续，只有在内核重启或者人工删除时，该消息队列才会被删除



#### 2.3.5 共享内存(share memory)

- 多个进程可以直接读写同一块内存空间，是最快的可用IPC方式
- 为了多个进程间交换信息，内核专门留出一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大地提高了效率
- 由于多个进程共享一段内存，因此需要依靠某种同步机制(如信号量)来达到进程间的同步及互斥



#### 2.3.6 信号量(semaphore)

- 信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步

- 为了获得共享资源，进程需要执行下列操作：
   （1）**创建一个信号量**：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。
   （2）**等待一个信号量**：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。
   （3）**挂出一个信号量**：该操作将信号量的值加1，也称为V操作。

- 为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。Linux环境中，有三种类型：**Posix（可移植性操作系统接口）有名信号量（使用Posix IPC名字标识）**、**Posix基于内存的信号量（存放在共享内存区中）**、**System V信号量（在内核中维护）**。这三种信号量都可用于进程间或线程间的同步。

  <img src="https://gitee.com/breeze1002/upic/raw/master/OS/os-1/2021%2010%2028%2010%2038%2003%201635388683%201635388683125%20ZemYsQ%20image-20210820093852923.png" alt="image-20210820093852923" style="zoom:35%" />

  

  > **信号量与普通整型变量的区别：**
  >  （1）信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap) ; 来进行访问；
  >  （2）操作也被成为PV原语（P来源于荷兰语proberen"测试"，V来源于荷兰语verhogen"增加"，P表示通过的意思，V表示释放的意思），而普通整型变量则可以在任何语句块中被访问；

  

> **信号量与互斥量之间的区别：**
>  （1）互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。
>  **互斥：**是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。
>  **同步：**是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。
>  在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源
>  （2）互斥量值只能为0/1，信号量值可以为非负整数。
>  也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。
>  （3）互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。



#### 2.3.7 套接字(socket)

- 套接字是一种通信机制，凭借这种机制，客户端/服务器可以通过网络实现进程间的通信
- 套接字时支持TCP/IP通信的基本操作单元，可以看做不同主机之间进程进行双向通信的端点





### 2.4  线程间的同步方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键资源使用冲突。

- **互斥量：** 采用互斥对象机制。只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，因此可以保证公共资源不会被多个线程同时访问。  (例如 Synchronized关键字 / Lock锁)
- **信号量：** 允许同一时刻多个线程访问同一资源，但需要控制同一时间访问该资源的最大线程数
- **事件：** wait/notify：通过通知操作的方式保持线程同步，还可以实现多线程优先级的比较操作



### 2.5 进程的调度算法

`为了确定进程的执行顺序以实现最大的CPU利用率`

- **先到先服务(FCFS):**从就绪队列中选择一个最先进入该队列的进程为其分配资源，并立即执行
- **短作业优先(SJF):** 从就绪队列中选择一个估计运行时间最短的进程为之分配资源，并立即执行
- **时间片轮转:** 每个进程被分配一个时间片来运行
- **多级反馈队列:** 短作业优先算法有一定的局限性(只照顾短进程而忽略了长进程)。 而多级反馈队列能使高优先级的作业得到响应又能使短作业迅速完成。因而时目前公认的一种较好的进程调度算法 （UNIX操作系统采用）
- **优先级调度:** 为每个进程分配优先级，首先执行优先级最高的进程，以此类推。相同的优先级采用FCFS  



## 三 操作系统内存管理基础

- **内存空间的分配与回收**
- **内存空间的扩充**
- **地址转换**
- **存储保护**





### 3.1 内存管理机制

- **连续分配管理方式:** 分配连续的内存空间
  - **块式管理**
    - 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片
- **非连续分配管理方式:** 离散的内存空间
  - **页式管理**
    - 把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
  - **段式管理**
    - 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
  - **段页式管理机制**
    - 段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。
- **分页机制与分段机制**
  - **共同点**
    - 都是为了提高内存利用率而生，会产生较少的内存碎片
    - 都是离散的分配管理方式。但是每个段/页内时连续的
  - **区别**
    - 页的大小固定，由操作系统决定 ； 段的大小不固定，取决于当前运行的程序
    - 分页仅仅是满足操作系统 内存管理的需求；而段是逻辑信息的单位，提现为可以区分为代码段，数据段等等



### 3.2 页表管理/快表/多级页表

- **页表管理机制**

  - 实现从进程的逻辑地址转换为内存的物理地址

    <img src="https://gitee.com/breeze1002/upic/raw/master/OS/os-1/2021%2010%2028%2010%2038%2006%201635388686%201635388686367%20BTlbmu%20image-20210822090212270.png" alt="image-20210822090212270" style="zoom:50%" />



- **快表**
  - **页表 存在的问题**
    - 页表存在与内存中，因此CPU存取一个数据，需要访问主存两次
      - 第一次：访问内存中的页表，找到物理块号，将此块号与业内地址拼接形成物理地址
      - 第二次：真正访问该物理地址，存取其中内容
    - 这样就把程序执行速度降低一倍，为了提高存取速度，在地址变换机构中增设一组寄存器，用于存放页表
  - **存放在高速缓冲寄存器(联想存贮器TLB)中的页表成为快表，** 内存中的页表成为慢表

- **多级页表**
  - 现在的计算机系统，支持非常大的逻辑地址空间(232 - 264)。因此页表就变得非常大，需要占用很大的内存空间
  - **利用局部性原理**    牺牲时间换取空间
    - **二级页表可以不存在：**  一级页表会覆盖整个虚拟地址空间，但是如果某个一级页表的页表项没有被用到，也就不需要创建这个页表对应的二级页表了。假设只有20%的一级页表项被使用到，那就会节省非常大的内存空间；
    - **二级页表可以不存在主存中：** 将二级页表存储在磁盘,需要时再去调用











## 四 虚拟内存

### 4.1 概念

虚拟内存是一种计算机系统的**内存管理技术**，它可以:

- **让程序可以拥有超过系统物理内存大小的可用内存空间**
- **为每个进程提供一片连续完整的内存空间，让每个进程产生一种自己在独享主存的错觉。**

> 实际上，它通常被分隔成多个物理内存碎片，还有部分暂时存储在硬盘上，在需要时进行数据交换。
>
> 与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等



### 4.2 局部性原理

**局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。**

> 以下内容摘自《计算机操作系统教程》 第 4 章存储器管理。

早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

- **时间局部性**是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。
- **空间局部性**通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。
- 虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。



### 4.3 虚拟内存的技术实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

**这里多说一下？很多人容易搞混请求分页与分页存储管理，两者有何不同呢？**

请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。

它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

不管是上面那种实现方式，我们一般都需要：

1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。



### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来**选择淘汰哪一页的规则叫做页面置换算法**，我们可以把页面置换算法看成是淘汰页面的规则。

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。







